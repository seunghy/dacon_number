# -*- coding: utf-8 -*-
"""dacon_number.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e6dFpWQHnibPaG_NuFspsd3d6Nq3e2CQ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from sklearn.preprocessing import OneHotEncoder
from tensorflow import keras
from tensorflow.keras.layers import *
from sklearn.model_selection import train_test_split


train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
print(train.shape)
train.head()

#r결측값 확인
print((test.isnull().sum(axis=1).values !=0).sum())
(train.isnull().sum(axis=1).values != 0).sum()

digit_labels = train['digit'].values
letter_labels = train['letter'].values
pix = train.iloc[:,3:].values
pix = pix.reshape(pix.shape[0],28,28)
pix = pix/255.0

test_pix = test.iloc[:,2:].values
test_pix = test_pix/255.0

plt.figure(figsize=(7,7))
i = 0

j = 1
for i in range(9):
  plt.subplot(3,3,j)
  plt.title('digit: {label}, alphabet: {alpha}'.format(label=digit_labels[i], alpha=letter_labels[i]))
  plt.imshow(pix[i]) #cmap="gray"
  plt.axis('off')
  j += 1
plt.show()

plt.figure(figsize=(7,7))
i = 0

j = 1
for i in range(9):
  plt.subplot(3,3,j)
  plt.title('digit: {label}, alphabet: {alpha}'.format(label=digit_labels[i], alpha=letter_labels[i]))
  temp = np.where((pix[i]*255)>130, pix[i], 0)
  plt.imshow(temp) #cmap="gray"
  plt.axis('off')
  j += 1
plt.show()

#알파벳으로 보이는 옅은 부분 0처리 후 새로운 pix 변수
pix = np.where((pix*255)>130, pix, 0)

# input_data = train.iloc[:,2:].values
encoder = OneHotEncoder().fit(train.iloc[:,2].values.reshape(-1,1))
alphabet_label = encoder.transform(train.iloc[:,2].values.reshape(-1,1)).toarray()
alphabet_label

input_data = np.hstack([alphabet_label, pix.reshape(train.shape[0], -1)])
input_data

encoder = OneHotEncoder().fit(digit_labels.reshape(-1,1))
digit_labels_onehot = encoder.transform(digit_labels.reshape(-1,1)).toarray()
digit_labels_onehot

"""### Train/Test split"""

x_train, x_val, y_train, y_val = train_test_split(pix, digit_labels_onehot, test_size=0.1)
x_train = tf.expand_dims(x_train, 3)
x_val = tf.expand_dims(x_val, 3)
print("train:",x_train.shape, y_train.shape)
print("test:",x_val.shape, y_val.shape)

"""### data augmentation"""

pix = tf.expand_dims(pix, 3)
pix.shape

###keras
tf.keras.backend.clear_session()
tf.keras.backend.set_floatx('float64')
data_aug = tf.keras.Sequential([
                                tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)
])

aug_image = data_aug(tf.expand_dims(pix[i], 0))
aug_image[0].shape
plt.figure(figsize=(7,7))
for i in range(9):
  aug_image = data_aug(tf.expand_dims(pix[i], 0))
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(tf.reshape(aug_image[0], shape=(28,28)))
  plt.axis("off")
 

# ###tf
# ##뒤집기
# flipped = tf.image.flip_left_rigth(image)
# ##그레이 스케일
# grayscaled = tf.image.rgb_to_grayscale(image)
# tf.sqeeze(grayscaled)
# ##이미지 채도
# saturated = tf.image.adjust_saturation(image, 3)
# ##밝기 변경
# bright = tf.image.adjust_brightness(image, 0.4)
# ##가운데 자르기(중앙에서 원하는 이미지 부분까지 자름)
# cropped = tf.image.central_crop(image, central_fraction=0.5)
# ##이미지 회전
# rotated = tf.image.rot90(image)
# def augment(image, label, img_size):
#   image = tf.image.resize_with_crop_or_pad(image, img_size+6, img_size+6)
#   image = tf.image.random_crop(image, size=[img_size, img_size, 3])
#   image = tf.image.random_brightness(image, max_delta=0.5)
#   image = tf.clip_by_value(image, 0, 1) #clip_by_value : 리스트에서 min보다 작은 값은 min, max보다 큰 값은 max
#   return image, label

traingen = tf.keras.preprocessing.image.ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=35,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
     
)

valgen = tf.keras.preprocessing.image.ImageDataGenerator(
    featurewise_center=True
     
)


#기본 CNN (with Maxpooling2D)
tf.keras.backend.clear_session()
model = tf.keras.Sequential([
                             tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same'),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same'),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Flatten(),
                             tf.keras.layers.Dense(512, activation='relu'),
                             tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.005), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()


traingen.fit(x_train)
valgen.fit(x_val)

model.fit(traingen.flow(x_train, y_train, batch_size=30), epochs=5, validation_data=valgen.flow(x_val, y_val),verbose = 1)

tf.squeeze(aug_image[0],2).shape

tf.reshape(aug_image[0], shape=(28,28)).shape

data_aug

"""### Simple DNN"""

# from keras.models import Sequential
# from keras.layers import LSTM, Dense, TimeDistributed
# from keras.utils import to_categorical


tf.keras.backend.clear_session()
model = tf.keras.models.Sequential([
                                    tf.keras.layers.Flatten(input_shape=(28,28)),
                                    tf.keras.layers.Dense(312, activation='relu'),
                                    tf.keras.layers.Dense(156, activation='relu'),
                                    tf.keras.layers.Dropout(0.1),
                                    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy']) #kullback_leibler_divergence
model.summary()

history = model.fit(pix, digit_labels_onehot,epochs=30, validation_split=0.3)

digit_labels_onehot.shape



"""### Simple DNN"""

# from keras.models import Sequential
# from keras.layers import LSTM, Dense, TimeDistributed
# from keras.utils import to_categorical


tf.keras.backend.clear_session()
model = tf.keras.models.Sequential([
                                    tf.keras.layers.Flatten(input_shape=(810,)),
                                    tf.keras.layers.Dense(312, activation='relu'),
                                    tf.keras.layers.BatchNormalization(),
                                    tf.keras.layers.Dense(156, activation='relu'),
                                    tf.keras.layers.BatchNormalization(),
                                    tf.keras.layers.Dropout(0.1),
                                    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy']) #kullback_leibler_divergence
model.summary()

history = model.fit(input_data, digit_labels_onehot,epochs=30, validation_split=0.3)



"""### Simple CNN --> 1번째 제출"""

#기본 CNN (with Maxpooling2D)
tf.keras.backend.clear_session()
model = tf.keras.Sequential([
                             tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Conv2D(128,(3,3), activation='relu', padding='same'),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Conv2D(256,(3,3), activation='relu', padding='same'),
                             tf.keras.layers.MaxPooling2D((2,2)),
                             tf.keras.layers.Dropout(0.5),
                             tf.keras.layers.Flatten(),
                             tf.keras.layers.Dense(512, activation='relu'),
                             tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer=tf.keras.optimizers.Adam(0.005), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

checkpoint_filepath = '/tmp/checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

history = model.fit(np.reshape(pix, pix.shape+(1,)), digit_labels_onehot, epochs=100, batch_size=30, validation_split=0.1, shuffle=True, callbacks=[model_checkpoint_callback]) #np.reshape(pix, pix.shape+(1,)): 3d->4d

model.load_weights(checkpoint_filepath)

np.reshape(pix, pix.shape+(1,)).shape

pred = model.predict(np.reshape(test_pix.reshape(test_pix.shape[0],28,28),test_pix.reshape(test_pix.shape[0],28,28).shape+(1,)))
pred.shape

ls

sub = pd.DataFrame({'id': test['id'], 'digit': tf.argmax(pred, axis=1)})
sub.to_csv("/submission_0811.csv", index=False, header=True, encoding='utf-8')

#기본 CNN(without Maxpooling2D & stride 변경)
tf.keras.backend.clear_session()
input_0 = tf.keras.Input(shape=(28,28,1))

layer = tf.keras.layers.Conv2D(64, kernel_size=2, activation='relu',padding='same')(input_0)
layer = tf.keras.layers.Conv2D(128, kernel_size=5, activation='relu',strides=(2,2), padding='same')(layer)
layer = tf.keras.layers.BatchNormalization()(layer)

layer = tf.keras.layers.Conv2D(128, kernel_size=3, activation='relu',padding='same')(layer)
layer = tf.keras.layers.BatchNormalization()(layer)
layer = tf.keras.layers.Conv2D(256, kernel_size=2, activation='relu',strides=(2,2), padding='same')(layer)
layer = tf.keras.layers.BatchNormalization()(layer)
layer = tf.keras.layers.Dropout(0.4)(layer)

layer = tf.keras.layers.Flatten()(layer)
layer = tf.keras.layers.Dense(1000, activation='relu')(layer)
output = tf.keras.layers.Dense(10, activation='softmax')(layer)

model = tf.keras.Model(inputs=input_0, outputs=output)

model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()



#기본 ResNet
tf.keras.backend.clear_session()
input_0 = tf.keras.Input(shape=(28,28,1))

layer = tf.keras.layers.Conv2D(32, 1,activation='relu')(input_0)
layer = tf.keras.layers.Conv2D(16, 1,activation='relu')(layer)
block_1 = tf.keras.layers.MaxPooling2D(1)(layer)

layer = tf.keras.layers.Conv2D(16, 1, activation='relu')(block_1)
layer = tf.keras.layers.Conv2D(16, 1,activation='relu')(layer)
layer = tf.keras.layers.Dropout(0.3)(layer)
block_2 = tf.keras.layers.add([layer, block_1])

layer = tf.keras.layers.Conv2D(16, 1, activation='relu')(block_2)
layer = tf.keras.layers.GlobalAveragePooling2D()(layer)
layer = tf.keras.layers.Dense(16, activation='relu')(layer)

output = tf.keras.layers.Dense(10, activation='softmax')(layer)

model = tf.keras.Model(inputs=input_0, outputs=output)

model.compile(optimizer=tf.keras.optimizers.Adam(0.005), loss='categorical_crossentropy', metrics=['accuracy'])
print(model.summary())

tf.keras.utils.plot_model(model, show_shapes=True)

"""### 학습"""

callback = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy', min_delta=50, patience=100, mode='auto',
    baseline=0.8, restore_best_weights=False
)

history = model.fit(np.reshape(pix, pix.shape+(1,)), digit_labels_onehot, epochs=10, batch_size=50, validation_split=0.1, shuffle=True, callbacks=[callback]) #np.reshape(pix, pix.shape+(1,)): 3d->4d

history.params

